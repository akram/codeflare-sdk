{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3260669-c7ec-4d06-a655-590c5e7ab152",
   "metadata": {},
   "source": [
    "# Transfer learning with Huggingface using CodeFlare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acfb10-1aa1-445d-947e-396ea5ebed1a",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to leverage the **[huggingface](https://huggingface.co/)** support in ray ecosystem to carry out a text classification task using transfer learning. We will be referencing the examples **[here](https://huggingface.co/docs/transformers/tasks/sequence_classification)** and **[here](https://docs.ray.io/en/latest/train/getting-started-transformers.html)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b77929-e96c-434e-ada3-8b14795bfbb1",
   "metadata": {},
   "source": [
    "The example carries out a text classification task on **[imdb dataset](https://huggingface.co/datasets/imdb)** and tries to classify the movie reviews as positive or negative. Huggingface library provides an easy way to build a model and the dataset to carry out this classification task. In this case we will be using **distilbert-base-uncased** model which is a **BERT** based model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02593d04-40b9-4a07-a32e-40b649444ab5",
   "metadata": {},
   "source": [
    "### Getting all the requirements in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c737a768-6e31-4767-a301-60ae932b4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0734734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logged into https://api.akram.3psf.p3.openshiftapps.com:443'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create authentication object for user permissions\n",
    "# IF unused, SDK will automatically check for default kubeconfig, then in-cluster config\n",
    "# KubeConfigFileAuthentication can also be used to specify kubeconfig path manually\n",
    "auth = TokenAuthentication(\n",
    "    token = \"XXXX\",\n",
    "    server = \"XXXX\",\n",
    "    skip_tls = False\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27f84c",
   "metadata": {},
   "source": [
    "Here, we want to define our cluster by specifying the resources we require for our batch workload. Below, we define our cluster object (which generates a corresponding Ray Cluster).\n",
    "\n",
    "NOTE: The default images used by the CodeFlare SDK for creating a RayCluster resource depend on the installed Python version:\n",
    "\n",
    "- For Python 3.9: 'quay.io/modh/ray:2.35.0-py39-cu121'\n",
    "- For Python 3.11: 'quay.io/modh/ray:2.35.0-py311-cu121'\n",
    "\n",
    "If you prefer to use a custom Ray image that better suits your needs, you can specify it in the image field to override the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220b9d85-3a3c-4c0c-aaf2-0d866823dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml resources loaded for hfgputest\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fec1006b0c6469e8cd42e31d9c95c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Cluster Up', icon='play', style=ButtonStyle(), tooltip='Creaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86a99fdb8dc46a9ae72d8d46afb520d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create our cluster and submit\n",
    "# The SDK will try to find the name of your default local queue based on the annotation \"kueue.x-k8s.io/default-queue\": \"true\" unless you specify the local queue manually below\n",
    "cluster_name= \"hfgputest\"\n",
    "cluster = Cluster(ClusterConfiguration(name=cluster_name, \n",
    "                                       head_extended_resource_requests={'nvidia.com/gpu':1}, # For GPU enabled workloads set the head_extended_resource_requests and worker_extended_resource_requests\n",
    "                                       worker_extended_resource_requests={'nvidia.com/gpu':1},\n",
    "                                       num_workers=1,\n",
    "                                       worker_cpu_requests=2, \n",
    "                                       worker_cpu_limits=3, \n",
    "                                       worker_memory_requests=8, \n",
    "                                       worker_memory_limits=8, \n",
    "                                       # image=\"\", # Optional Field \n",
    "                                       write_to_file=False, # When enabled Ray Cluster yaml files are written to /HOME/.codeflare/resources \n",
    "                                       # local_queue=\"local-queue-name\" # Specify the local queue manually\n",
    "                                       ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eef53c",
   "metadata": {},
   "source": [
    "Next, we want to bring our cluster up, so we call the `up()` function below to submit our Ray Cluster onto the queue, and begin the process of obtaining our resource cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1d861-b743-4c05-903b-5799072b942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ebdfb",
   "metadata": {},
   "source": [
    "Now, we want to check on the initial status of our resource cluster, then wait until it is finally ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0db5f5-22f1-4806-ae7e-a0ee865625c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                 </span><span style=\"font-weight: bold; font-style: italic\"> ðŸš€ CodeFlare Cluster Status ðŸš€</span><span style=\"font-style: italic\">                  </span>\n",
       "<span style=\"font-weight: bold\">                                                                  </span>\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #008000; font-weight: bold\">Name</span>                                                       â”‚ \n",
       " â”‚   <span style=\"font-weight: bold; text-decoration: underline\">hfgputest</span>                                      Active âœ…   â”‚ \n",
       " â”‚                                                              â”‚ \n",
       " â”‚   <span style=\"font-weight: bold\">URI:</span> ray://hfgputest-head-svc.akram.svc:10001              â”‚ \n",
       " â”‚                                                              â”‚ \n",
       " â”‚   <a href=\"https://ray-dashboard-hfgputest-akram.apps.rosa.akram.3psf.p3.openshiftapps.com\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">DashboardðŸ”—</span></a>                                                â”‚ \n",
       " â”‚                                                              â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                 \u001b[0m\u001b[1;3m ðŸš€ CodeFlare Cluster Status ðŸš€\u001b[0m\u001b[3m                  \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m                                                                \u001b[0m\u001b[1m \u001b[0m\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   \u001b[1;37;42mName\u001b[0m                                                       â”‚ \n",
       " â”‚   \u001b[1;4mhfgputest\u001b[0m                                      Active âœ…   â”‚ \n",
       " â”‚                                                              â”‚ \n",
       " â”‚   \u001b[1mURI:\u001b[0m ray://hfgputest-head-svc.akram.svc:10001              â”‚ \n",
       " â”‚                                                              â”‚ \n",
       " â”‚   \u001b]8;id=223641;https://ray-dashboard-hfgputest-akram.apps.rosa.akram.3psf.p3.openshiftapps.com\u001b\\\u001b[4;34mDashboardðŸ”—\u001b[0m\u001b]8;;\u001b\\                                                â”‚ \n",
       " â”‚                                                              â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<CodeFlareClusterStatus.READY: 1>, True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.status()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed6d7f59-4900-419f-a7c4-0277ff954fcc",
   "metadata": {},
   "source": [
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2969a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ac246",
   "metadata": {},
   "source": [
    "Let's quickly verify that the specs of the cluster are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a54428-f186-4c27-948e-4eaf9c0e34b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                 </span><span style=\"font-weight: bold; font-style: italic\"> ðŸš€ CodeFlare Cluster Details ðŸš€</span><span style=\"font-style: italic\">                  </span>\n",
       "<span style=\"font-weight: bold\">                                                                   </span>\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #008000; font-weight: bold\">Name</span>                                                        â”‚ \n",
       " â”‚   <span style=\"font-weight: bold; text-decoration: underline\">hfgputest</span>                                      Active âœ…    â”‚ \n",
       " â”‚                                                               â”‚ \n",
       " â”‚   <span style=\"font-weight: bold\">URI:</span> ray://hfgputest-head-svc.akram.svc:10001               â”‚ \n",
       " â”‚                                                               â”‚ \n",
       " â”‚   <a href=\"https://ray-dashboard-hfgputest-akram.apps.rosa.akram.3psf.p3.openshiftapps.com\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">DashboardðŸ”—</span></a>                                                 â”‚ \n",
       " â”‚                                                               â”‚ \n",
       " â”‚  <span style=\"font-style: italic\">                     Cluster Resources                     </span>  â”‚ \n",
       " â”‚   â•­â”€â”€ Workers â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker specs(each) â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®   â”‚ \n",
       " â”‚   â”‚ <span style=\"font-weight: bold\"> # Workers </span> â”‚  â”‚ <span style=\"font-weight: bold\"> Memory      CPU         GPU        </span> â”‚   â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> â”‚   â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\"> 1         </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\"> 8G~8G      </span><span style=\"color: #800080; text-decoration-color: #800080\"> 2~3         1          </span> â”‚   â”‚ \n",
       " â”‚   â”‚ <span style=\"color: #800080; text-decoration-color: #800080\">           </span> â”‚  â”‚ <span style=\"color: #008080; text-decoration-color: #008080\">            </span><span style=\"color: #800080; text-decoration-color: #800080\">                        </span> â”‚   â”‚ \n",
       " â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯   â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                 \u001b[0m\u001b[1;3m ðŸš€ CodeFlare Cluster Details ðŸš€\u001b[0m\u001b[3m                  \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m                                                                 \u001b[0m\u001b[1m \u001b[0m\n",
       " â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® \n",
       " â”‚   \u001b[1;37;42mName\u001b[0m                                                        â”‚ \n",
       " â”‚   \u001b[1;4mhfgputest\u001b[0m                                      Active âœ…    â”‚ \n",
       " â”‚                                                               â”‚ \n",
       " â”‚   \u001b[1mURI:\u001b[0m ray://hfgputest-head-svc.akram.svc:10001               â”‚ \n",
       " â”‚                                                               â”‚ \n",
       " â”‚   \u001b]8;id=531351;https://ray-dashboard-hfgputest-akram.apps.rosa.akram.3psf.p3.openshiftapps.com\u001b\\\u001b[4;34mDashboardðŸ”—\u001b[0m\u001b]8;;\u001b\\                                                 â”‚ \n",
       " â”‚                                                               â”‚ \n",
       " â”‚  \u001b[3m                     Cluster Resources                     \u001b[0m  â”‚ \n",
       " â”‚   â•­â”€â”€ Workers â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker specs(each) â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®   â”‚ \n",
       " â”‚   â”‚ \u001b[1m \u001b[0m\u001b[1m# Workers\u001b[0m\u001b[1m \u001b[0m â”‚  â”‚ \u001b[1m \u001b[0m\u001b[1mMemory    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCPU       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mGPU       \u001b[0m\u001b[1m \u001b[0m â”‚   â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m â”‚   â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m1        \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m8G~8G     \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m2~3       \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m1         \u001b[0m\u001b[35m \u001b[0m â”‚   â”‚ \n",
       " â”‚   â”‚ \u001b[35m \u001b[0m\u001b[35m         \u001b[0m\u001b[35m \u001b[0m â”‚  â”‚ \u001b[36m \u001b[0m\u001b[36m          \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m\u001b[35m \u001b[0m\u001b[35m          \u001b[0m\u001b[35m \u001b[0m â”‚   â”‚ \n",
       " â”‚   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯   â”‚ \n",
       " â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RayCluster(name='hfgputest', status=<RayClusterStatus.READY: 'ready'>, head_cpu_requests=2, head_cpu_limits=2, head_mem_requests='8G', head_mem_limits='8G', num_workers=1, worker_mem_requests='8G', worker_mem_limits='8G', worker_cpu_requests=2, worker_cpu_limits=3, namespace='akram', dashboard='https://ray-dashboard-hfgputest-akram.apps.rosa.akram.3psf.p3.openshiftapps.com', worker_extended_resources={'nvidia.com/gpu': 1}, head_extended_resources={'nvidia.com/gpu': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac46c87-70f1-4c70-9648-881151665355",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_cluster_uri = cluster.cluster_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d65c3c",
   "metadata": {},
   "source": [
    "Now we can connect directly to our Ray cluster via the Ray python client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60276d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codeflare_sdk import generate_cert\n",
    "# Create required TLS cert and export the environment variables to enable TLS\n",
    "generate_cert.generate_tls_cert(cluster_name, cluster.config.namespace)\n",
    "generate_cert.export_env(cluster_name, cluster.config.namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dba6a0-8275-4726-8911-6b6ec467b6a3",
   "metadata": {},
   "source": [
    "**NOTE**: Now we have our resource cluster with the desired GPUs, so we can interact with it to train the HuggingFace model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c458589-5a17-47c6-a8db-625427ae4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SIGTERM handler is not set because current thread is not the main thread.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray cluster is up and running:  True\n",
      "https://akram-rhoaieng-1990.s3.eu-north-1.amazonaws.com/\n",
      "storage_path:  s3://akram-rhoaieng-1990/data/\n",
      "checkpoint_config:  CheckpointConfig(num_to_keep=3)\n",
      "run_config:  RunConfig(storage_path='s3://akram-rhoaieng-1990/data/', checkpoint_config=CheckpointConfig(num_to_keep=3), verbose=1)\n",
      "scaling_config:  ScalingConfig(num_workers=2, use_gpu=True)\n"
     ]
    }
   ],
   "source": [
    "#before proceeding make sure the cluster exists and the uri is not empty\n",
    "assert ray_cluster_uri, \"Ray cluster needs to be started and set before proceeding\"\n",
    "\n",
    "import ray\n",
    "import os\n",
    "from ray.train import CheckpointConfig, RunConfig\n",
    "from ray.train import ScalingConfig\n",
    "\n",
    "# reset the ray context in case there's already one. \n",
    "ray.shutdown()\n",
    "# establish connection to ray cluster\n",
    "\n",
    "# install additional libraries that will be required for this training\n",
    "runtime_env = {\"pip\": [\"transformers==4.41.2\", \n",
    "                       \"datasets==2.17.0\", \n",
    "                       \"accelerate==0.31.0\", \n",
    "                       \"scikit-learn==1.5.0\"]}\n",
    "\n",
    "# NOTE: This will work for in-cluster notebook servers (RHODS/ODH), but not for local machines\n",
    "# To see how to connect from your laptop, go to demo-notebooks/additional-demos/local_interactive.ipynb\n",
    "ray.init(address=ray_cluster_uri, runtime_env=runtime_env)\n",
    "\n",
    "print(\"Ray cluster is up and running: \", ray.is_initialized())\n",
    "\n",
    "bucket_name = os.getenv(\"AWS_S3_BUCKET\", \"default_bucket_name\")  # Use a default value if the env var is not set\n",
    "storage_path = f\"s3://{bucket_name}/data/\"\n",
    "print(os.getenv(\"AWS_S3_ENDPOINT\"))\n",
    "print(\"storage_path: \", storage_path)\n",
    "\n",
    "checkpoint_config = CheckpointConfig(num_to_keep=3)\n",
    "print(\"checkpoint_config: \", checkpoint_config)\n",
    "\n",
    "run_config = ray.train.RunConfig(storage_path=storage_path, \n",
    "                                 checkpoint_config=checkpoint_config)\n",
    "print(\"run_config: \", run_config)\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=2, use_gpu=True)\n",
    "print(\"scaling_config: \", scaling_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a38146-1321-4b7b-9152-9ebca4eb9444",
   "metadata": {},
   "source": [
    "**NOTE** : in this case since we are running a task for which we need additional pip packages. we can install those by passing them in the `runtime_env` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1945b-d6c8-49b8-9a4c-b82724cffba9",
   "metadata": {},
   "source": [
    "### Transfer learning code from huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdbe888-4f38-4e9a-ae43-67ce89ff9d42",
   "metadata": {},
   "source": [
    "We are using the code based on the examples **[here](https://huggingface.co/docs/transformers/tasks/sequence_classification)** and **[here](https://docs.ray.io/en/latest/train/getting-started-transformers.html)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e69994b4-1a13-43fe-b698-2a5374cb941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train_fn():\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from datasets import load_dataset, load_metric\n",
    "    import transformers\n",
    "    from transformers import (\n",
    "        Trainer,\n",
    "        TrainingArguments,\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSequenceClassification,\n",
    "    )\n",
    "    import ray.train.huggingface.transformers\n",
    "    from ray.train.torch import TorchTrainer\n",
    "\n",
    "    # When running in a multi-node cluster you will need persistent storage that is accessible across all worker nodes. \n",
    "    # See www.github.com/project-codeflare/codeflare-sdk/tree/main/docs/s3-compatible-storage.md for more information.\n",
    "    \n",
    "    def train_func():\n",
    "        # Datasets\n",
    "        dataset = load_dataset(\"imdb\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "        small_train_dataset = (\n",
    "            dataset[\"train\"].select(range(100)).map(tokenize_function, batched=True)\n",
    "        )\n",
    "        small_eval_dataset = (\n",
    "            dataset[\"test\"].select(range(100)).map(tokenize_function, batched=True)\n",
    "        )\n",
    "\n",
    "        # Model\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"distilbert-base-uncased\", num_labels=2\n",
    "        )\n",
    "\n",
    "        def compute_metrics(eval_pred):\n",
    "            metric = load_metric(\"accuracy\")\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "            return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "        # Hugging Face Trainer\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"test_trainer\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            report_to=\"none\",\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=small_train_dataset,\n",
    "            eval_dataset=small_eval_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        callback = ray.train.huggingface.transformers.RayTrainReportCallback()\n",
    "        trainer.add_callback(callback)\n",
    "        trainer = ray.train.huggingface.transformers.prepare_trainer(trainer)\n",
    "        trainer.train()\n",
    "    ray_trainer = TorchTrainer(\n",
    "        train_func,\n",
    "        scaling_config=scaling_config,\n",
    "        run_config=run_config\n",
    "        # Configure persistent storage that is accessible across \n",
    "        # all worker nodes.\n",
    "        # Uncomment and update the RunConfig below to include your storage details.\n",
    "        # run_config=ray.train.RunConfig(storage_path=\"storage path\"),\n",
    "    )\n",
    "    result: ray.train.Result = ray_trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9593fee-2b2b-415f-8902-bceec014385f",
   "metadata": {},
   "source": [
    "**NOTE:** This code will produce a lot of output and will run for **approximately 2 minutes.** As a part of execution it will download the `imdb` dataset, `distilbert-base-uncased` model and then will start transfer learning task for training the model with this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f0985e9-5e88-4d36-ab38-c3001c13f97c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(OSError)",
     "evalue": "\u001b[36mray::train_fn()\u001b[39m (pid=30872, ip=10.129.2.37)\n  File \"/tmp/ipykernel_10124/2969632525.py\", line 73, in train_fn\n  File \"/tmp/ray/session_2024-11-15_14-27-34_990179_1/runtime_resources/pip/9722261244c711db4e388426f42e7dd7dd95f293/virtualenv/lib64/python3.11/site-packages/ray/train/base_trainer.py\", line 589, in fit\n    storage = StorageContext(\n              ^^^^^^^^^^^^^^^\n  File \"/tmp/ray/session_2024-11-15_14-27-34_990179_1/runtime_resources/pip/9722261244c711db4e388426f42e7dd7dd95f293/virtualenv/lib64/python3.11/site-packages/ray/train/_internal/storage.py\", line 455, in __init__\n    self._create_validation_file()\n  File \"/tmp/ray/session_2024-11-15_14-27-34_990179_1/runtime_resources/pip/9722261244c711db4e388426f42e7dd7dd95f293/virtualenv/lib64/python3.11/site-packages/ray/train/_internal/storage.py\", line 483, in _create_validation_file\n    self.storage_filesystem.create_dir(self.experiment_fs_path)\n  File \"pyarrow/_fs.pyx\", line 612, in pyarrow._fs.FileSystem.create_dir\n  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\nOSError: When testing for existence of bucket 'akram-rhoaieng-1990': AWS Error ACCESS_DENIED during HeadBucket operation: No response body.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(OSError)\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#call the above cell as a remote ray function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/ray/_private/client_mode_hook.py:102\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client_mode_should_convert():\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Legacy code\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# we only convert init function if RAY_CLIENT_MODE=1\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/ray/util/client/api.py:42\u001b[0m, in \u001b[0;36m_ClientAPI.get\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, vals, \u001b[38;5;241m*\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"get is the hook stub passed on to replace `ray.get`\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        vals: [Client]ObjectRef or list of these refs to retrieve.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        timeout: Optional timeout in milliseconds\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/ray/util/client/worker.py:433\u001b[0m, in \u001b[0;36mWorker.get\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m    431\u001b[0m     op_timeout \u001b[38;5;241m=\u001b[39m max_blocking_operation_time\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_get\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GetTimeoutError:\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.11/site-packages/ray/util/client/worker.py:461\u001b[0m, in \u001b[0;36mWorker._get\u001b[0;34m(self, ref, timeout)\u001b[0m\n\u001b[1;32m    459\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to deserialize \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(chunk\u001b[38;5;241m.\u001b[39merror))\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mtotal_size \u001b[38;5;241m>\u001b[39m OBJECT_TRANSFER_WARNING_SIZE \u001b[38;5;129;01mand\u001b[39;00m log_once(\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_object_transfer_size_warning\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    464\u001b[0m ):\n\u001b[1;32m    465\u001b[0m     size_gb \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtotal_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m\n",
      "\u001b[0;31mRayTaskError(OSError)\u001b[0m: \u001b[36mray::train_fn()\u001b[39m (pid=30872, ip=10.129.2.37)\n  File \"/tmp/ipykernel_10124/2969632525.py\", line 73, in train_fn\n  File \"/tmp/ray/session_2024-11-15_14-27-34_990179_1/runtime_resources/pip/9722261244c711db4e388426f42e7dd7dd95f293/virtualenv/lib64/python3.11/site-packages/ray/train/base_trainer.py\", line 589, in fit\n    storage = StorageContext(\n              ^^^^^^^^^^^^^^^\n  File \"/tmp/ray/session_2024-11-15_14-27-34_990179_1/runtime_resources/pip/9722261244c711db4e388426f42e7dd7dd95f293/virtualenv/lib64/python3.11/site-packages/ray/train/_internal/storage.py\", line 455, in __init__\n    self._create_validation_file()\n  File \"/tmp/ray/session_2024-11-15_14-27-34_990179_1/runtime_resources/pip/9722261244c711db4e388426f42e7dd7dd95f293/virtualenv/lib64/python3.11/site-packages/ray/train/_internal/storage.py\", line 483, in _create_validation_file\n    self.storage_filesystem.create_dir(self.experiment_fs_path)\n  File \"pyarrow/_fs.pyx\", line 612, in pyarrow._fs.FileSystem.create_dir\n  File \"pyarrow/error.pxi\", line 92, in pyarrow.lib.check_status\nOSError: When testing for existence of bucket 'akram-rhoaieng-1990': AWS Error ACCESS_DENIED during HeadBucket operation: No response body."
     ]
    }
   ],
   "source": [
    "#call the above cell as a remote ray function\n",
    "ray.get(train_fn.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8cd32",
   "metadata": {},
   "source": [
    "Finally, we bring our resource cluster down and release/terminate the associated resources, bringing everything back to the way it was before our cluster was brought up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec421113-0e49-4043-a3b5-66efa5021cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a183b-5e8e-4adb-b9a6-a349e13512a0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "As shown in the above example, you can run your Huggingface transfer learning tasks easily and natively on CodeFlare. You can scale them from 1 to n GPUs without requiring you to make any significant code changes and leveraging the native Huggingface trainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677c868-a052-4893-9493-6f1dacd8fa27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
